{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e31f3-3310-4fe5-ace5-5d7f46c3f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment:\n",
    "Applying RNN on E-commerce recommendation system \n",
    "The goal here is to predict the next item a customer will purchase based on their purchase history,\n",
    "which is a classic application of Recurrent Neural Networks (RNNs) in recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea375cbe-845a-47f9-8081-0812092e06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique items (StockCode): 3659\n",
      "Total number of customer sequences: 4335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data.csv\", encoding='latin-1')\n",
    "\n",
    "# --- 1. Data Cleaning ---\n",
    "# Remove rows with missing CustomerID (we need to track user sequences)\n",
    "df.dropna(subset=['CustomerID'], inplace=True)\n",
    "df['CustomerID'] = df['CustomerID'].astype(int)\n",
    "\n",
    "# Filter out non-stock items (like POST, D, etc. typically cancelled or shipping)\n",
    "df = df[~df['StockCode'].astype(str).str.contains('^[a-zA-Z]', na=False)]\n",
    "\n",
    "# Filter out canceled transactions (InvoiceNo starts with 'C') and ensure positive quantity\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "df = df[df['Quantity'] > 0]\n",
    "\n",
    "# --- 2. Create Sequential Data ---\n",
    "# Convert InvoiceDate to datetime and sort by CustomerID and purchase time\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df.sort_values(by=['CustomerID', 'InvoiceDate'], inplace=True)\n",
    "\n",
    "# Group by CustomerID and aggregate the sequence of purchased StockCodes\n",
    "customer_sequences = df.groupby('CustomerID')['StockCode'].apply(list).reset_index()\n",
    "\n",
    "# --- 3. Item Encoding (Vocabulary Mapping) ---\n",
    "# Create a vocabulary of all unique StockCodes (items)\n",
    "all_items = df['StockCode'].unique()\n",
    "item_to_int = {item: i + 1 for i, item in enumerate(all_items)} # +1 for padding (0)\n",
    "int_to_item = {i + 1: item for i, item in enumerate(all_items)}\n",
    "num_items = len(all_items) + 1 # Total vocabulary size including 0 (padding)\n",
    "\n",
    "print(f\"Total number of unique items (StockCode): {num_items - 1}\")\n",
    "print(f\"Total number of customer sequences: {len(customer_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800a934a-811c-46c5-94d6-0084df1e236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Input Shape: (392035, 10)\n",
      "Target Shape: (392035,)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Sequence and Target Generation ---\n",
    "X_data = [] # Input sequence (e.g., [I1, I2, I3])\n",
    "y_data = [] # Target item (e.g., I4)\n",
    "MAX_SEQUENCE_LENGTH = 10 # Define a fixed maximum history length to use\n",
    "\n",
    "for sequence in customer_sequences['StockCode']:\n",
    "    # Map item strings to their integer IDs\n",
    "    encoded_sequence = [item_to_int[item] for item in sequence]\n",
    "    \n",
    "    # Create (Input, Target) pairs for every subsequence longer than 1\n",
    "    for i in range(1, len(encoded_sequence)):\n",
    "        # Input: The sequence up to item i\n",
    "        input_seq = encoded_sequence[:i]\n",
    "        # Target: The item at step i (the next item)\n",
    "        target_item = encoded_sequence[i]\n",
    "        \n",
    "        # Truncate the input sequence to the max length (only keep the MAX_SEQUENCE_LENGTH most recent items)\n",
    "        if len(input_seq) > MAX_SEQUENCE_LENGTH:\n",
    "            input_seq = input_seq[-MAX_SEQUENCE_LENGTH:]\n",
    "            \n",
    "        X_data.append(input_seq)\n",
    "        y_data.append(target_item)\n",
    "\n",
    "# --- 5. Padding and Splitting ---\n",
    "# Pad input sequences to ensure uniform length\n",
    "X_padded = pad_sequences(X_data, maxlen=MAX_SEQUENCE_LENGTH, padding='pre') # Padding before the sequence\n",
    "y_targets = np.array(y_data)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_padded, y_targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Padded Input Shape: {X_padded.shape}\")\n",
    "print(f\"Target Shape: {y_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512f2512-2fda-414d-b202-796c38f8948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">183,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3660</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">237,900</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │         \u001b[38;5;34m183,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m29,440\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3660\u001b[0m)                │         \u001b[38;5;34m237,900\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,340</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450,340\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,340</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450,340\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Functional API Version to resolve the warning ---\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Conceptual Parameters (reusing from previous steps)\n",
    "# num_items = 50001\n",
    "# EMBEDDING_DIM = 50\n",
    "# MAX_SEQUENCE_LENGTH = 10\n",
    "\n",
    "# 1. Define the input layer\n",
    "input_sequence = Input(shape=(MAX_SEQUENCE_LENGTH,), name='input_sequence')\n",
    "\n",
    "# 2. Embedding Layer\n",
    "embedded_sequence = Embedding(input_dim=num_items, \n",
    "                              output_dim=EMBEDDING_DIM, \n",
    "                              input_length=MAX_SEQUENCE_LENGTH)(input_sequence)\n",
    "\n",
    "# 3. LSTM Layer\n",
    "lstm_output = LSTM(64)(embedded_sequence)\n",
    "\n",
    "# 4. Output Layer\n",
    "predictions = Dense(num_items, activation='softmax')(lstm_output)\n",
    "\n",
    "# 5. Create the Model instance\n",
    "model_rnn_rec_functional = Model(inputs=input_sequence, outputs=predictions)\n",
    "\n",
    "# Compile the model (rest remains the same)\n",
    "model_rnn_rec_functional.compile(optimizer='adam', \n",
    "                                 loss='sparse_categorical_crossentropy', \n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "model_rnn_rec_functional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb39dac8-3740-4d15-acbc-18f7f174a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training RNN Model for Next Item Prediction ---\n",
      "Epoch 1/5\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.0076 - loss: 7.2918 - val_accuracy: 0.0133 - val_loss: 7.0328\n",
      "Epoch 2/5\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 22ms/step - accuracy: 0.0250 - loss: 6.6697 - val_accuracy: 0.0357 - val_loss: 6.4627\n",
      "Epoch 3/5\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.0461 - loss: 6.2822 - val_accuracy: 0.0512 - val_loss: 6.2788\n",
      "Epoch 4/5\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 22ms/step - accuracy: 0.0618 - loss: 6.0981 - val_accuracy: 0.0647 - val_loss: 6.1852\n",
      "Epoch 5/5\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 22ms/step - accuracy: 0.0769 - loss: 5.9711 - val_accuracy: 0.0749 - val_loss: 6.1290\n",
      "\n",
      "RNN Recommender Test Loss: 6.1290\n",
      "RNN Recommender Test Accuracy (Next Item Prediction): 0.0749\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Train the Model ---\n",
    "# Note: Training on the full dataset can be time-consuming, using few epochs for demonstration\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print(\"\\n--- Training RNN Model for Next Item Prediction ---\")\n",
    "history_rec = model_rnn_rec.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# --- 7. Evaluate the Model ---\n",
    "loss, accuracy = model_rnn_rec.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nRNN Recommender Test Loss: {loss:.4f}\")\n",
    "print(f\"RNN Recommender Test Accuracy (Next Item Prediction): {accuracy:.4f}\")\n",
    "# Note: Accuracy is a strict metric here (it must be the EXACT next item).\n",
    "# In real-world recommender systems, metrics like Recall@K or NDCG@K are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4630a6f9-1c39-48c2-afed-eab8146a3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommendation for Customer ID: 17262 ---\n",
      "Last items purchased: ['47566', '71053', '47566', '21896', '22076', '21925', '48138', '75049L', '23053', '23050']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
      "\n",
      "Top 5 Next Item Recommendations: ['23052', '23053', '23051', '23050', '23049']\n"
     ]
    }
   ],
   "source": [
    "def predict_next_item(model, user_history_items, item_to_int, int_to_item, max_len, k=5):\n",
    "    # 1. Encode and Truncate the history\n",
    "    encoded_history = [item_to_int.get(item, 0) for item in user_history_items]\n",
    "    if len(encoded_history) > max_len:\n",
    "        encoded_history = encoded_history[-max_len:]\n",
    "    \n",
    "    # 2. Pad the sequence\n",
    "    padded_input = pad_sequences([encoded_history], maxlen=max_len, padding='pre')\n",
    "    \n",
    "    # 3. Predict the probabilities for all items\n",
    "    predictions = model.predict(padded_input)[0]\n",
    "    \n",
    "    # 4. Get the top K item indices (IDs)\n",
    "    # np.argsort returns indices that would sort the array (ascending), [-k:] gets the top k indices\n",
    "    top_k_indices = np.argsort(predictions)[-k:][::-1]\n",
    "    \n",
    "    # 5. Map back to StockCodes\n",
    "    recommended_items = [int_to_item.get(idx, 'UNKNOWN_ITEM') for idx in top_k_indices if idx != 0]\n",
    "\n",
    "    return recommended_items\n",
    "\n",
    "# Example: Pick a random customer's last MAX_SEQUENCE_LENGTH items\n",
    "sample_user_id = customer_sequences['CustomerID'].sample(1).iloc[0]\n",
    "sample_history = customer_sequences[customer_sequences['CustomerID'] == sample_user_id]['StockCode'].iloc[0]\n",
    "# Use the last MAX_SEQUENCE_LENGTH items as the input sequence for prediction\n",
    "input_history = sample_history[-MAX_SEQUENCE_LENGTH:]\n",
    "\n",
    "print(f\"\\n--- Recommendation for Customer ID: {sample_user_id} ---\")\n",
    "print(f\"Last items purchased: {input_history}\")\n",
    "\n",
    "# Get the top 5 recommendations\n",
    "recommendations = predict_next_item(model_rnn_rec, input_history, item_to_int, int_to_item, MAX_SEQUENCE_LENGTH, k=5)\n",
    "\n",
    "print(f\"\\nTop 5 Next Item Recommendations: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7713ae-68d5-4454-8ed5-1158751dece6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
